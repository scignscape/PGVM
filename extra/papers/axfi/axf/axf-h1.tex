
\part{Hypergraph Text Encoding Protocol}
\section{Overview}

\p{The Hypergraph Text Encoding Protocol is a 
framework for detailed encoding of text 
documents.  \HTXN{} is not a markup language, 
although the \HTXN{} \q{Reference Implementation} 
includes a new markup format (called \NGML{}, or 
\q{Next Generation Markup Language}) which 
is one way to create \HTXN{} documents.  
Instead, \HTXN{} is a binary encoding that can 
represent the structure of several different 
markup formats, including \XML{}, \LaTeX{}, and 
\RDF{}.  \HTXN{} allows document collections to 
have a common representation, even if the 
original documents are in different 
formats.  \HTXN{} also facilitates converting 
between formats; for example, one document 
can be represented in both \LaTeX{} and \XML{}.}

\p{The motivations for \HTXN{} are both practical and technological.  
Practically speaking, mismatch between document formats 
can be a noticeable impediment to editing and fine-tuning 
publications, and integrating them into digital 
ecosystems.  For example, converting from \LaTeX{} to 
\XML{} discards document anchors and auxiliary data 
that could be used to externally cite specific 
locations in a publication (\q{Micro-Citations} go 
hand-in-hand with fine-grained textual annotations, because 
\PDF{} viewers can, given proper metadata, browse to 
the exact line where a person, data structure, or 
technical concept appears in a document).  Technologically, 
different formats each have their own unique virtues.  
\LargeLaTeX{}, in many people's opinion, creates the 
most visually compelling documents, and also has sophisticated 
auxiliary-file and data-generation features 
(this auxiliary data is increasingly important 
in a publishing industry where text-based 
content, such as \PDF{} files, are only one part of an 
integrated digital platform).  \LargeLaTeX{}, however, has no 
established proofing and change-tracking protocol.  
\XML{} is architecturally well-designed for multi-party 
editing and tracking, but typically yields 
mediocre (\HTML{}-based) renderings.  \RDF{}, by supporting concurrent 
and overlapping markup, is more expressive than 
\XML{} and \LaTeX{}, but it lacks \LaTeX{}'s pre-processing 
(auxiliary data) capabilities as well as \XML{}'s 
post-processing document-interaction functionality.}

\p{Rather than accept the limitations of any one format, 
\HTXN{} embraces a philosophy of encoding documents 
in its own internal system, then generating 
\q{views} onto the document in a range of structures, 
so as to benefit from different formats' features 
at different stages of finalizing a publication.  
An \HTXN{} file may be converted to \LaTeX{} to 
generate auxiliary data, then converted to 
\XML{} for collaborative editing, and finally 
converted to \RDF{} (or another graph representation) 
for searching and indexing.}

%\vspace{2em}
%\noindent\lun{Features}
%{\sectsp}
\subsection{HTXN Features}

\p{Apart from its overarching philosophy, 
\HTXN{}'s distinguishing features include:

\begin{enumerate}
\item{} A unified document-structure model which accommodates 
the idiosyncracies of different markup styles, 
such as attribute child nodes in \XML{}, 
optional arguments in \LaTeX{}, subject defaults in 
\RDF{}, and concurrent/overlapping markup as in \TeXMECS{}. 

\item{} An encoding built from the ground up to support 
multi-party editing and collaboration.  Internally, 
\HTXN{} uses \q{stand-off} annotations which logically 
separate markup content from the underlying text.  
Multiple sources can thereby contribute distinct 
markup structure, which may be used, for example, 
to differentiate document changes made by 
authors from those made by editors.

\item{} A convenient architecture for \q{subordinate} documents which 
expose some restricted portion of their \q{parent} documents.  
This is also useful for editing.  Starting with an overall 
\HTXN{} parent, one can selectively create a subordinate document 
which (for example) includes only editable text, yielding 
a simplified version of the document suitable for 
textual revisions.  After editing, changes made to the 
subordinate document are then folded into its parent.

\item{} A detailed system for pairing documents with external 
data and data sets.  In particular, \HTXN{} supports document 
anchors allowing structured data within a data set to 
reference locations in accompanying publications.  These 
back-references could be used, for example, to identify 
points in a publication where there is a definition, 
explanation, review, or visualization of technical concepts 
and/or data aggregates introduced in a data set.  Unlike 
\LaTeX{} references or \HTML{} anchors, these \HTXN{} anchors 
are data-specific and logically separated from textual 
cross-references. 

\item{} Several special features for data-based annotations, 
or ascribing metadata or interpretations to text 
segments which conform to structured data types 
(proper names, acronyms, dates, times, magnitudes, etc.).  
This includes numeric types typically unrepresented 
in most markup formats, such as range-delimited 
integer types and \q{Universal Numbers}, or \q{posits}, 
a recent alternative to floating-point decimals.  

\item{} Functionality for creating data sets directly 
from the text itself.  For instance, example 
sentences used within linguistic publications, 
to illustrate semantic or syntactic principles, 
can be compiled as a sentence-corpus to produce 
a distinct data set associated with the 
original publication.  Larger corpora can then 
be compiled from collections of linguistic 
texts.  Similar techniques can be employed 
in analogous \q{digital humanities} contexts; 
for example, extracting a corpus of discussions 
about cultural artifacts by extracting sentences 
or paragraphs pertaining to an 
externally identifiable object (such as an 
artwork held in a museum).   

\item{} A framework for \q{complex microcitations}, meaning 
individually citable locations in a document which involve 
multipart data structures.  A case study would be linguistic 
examples that display (alongside or within a sentence) supplemental 
visual cues such as intonation, prosody, lexical category, 
morphology, or grammatical-structural annotations.  
Such material needs special typesetting instructions, but 
the visual format in turn depends on formal sentence 
models.  For another example, graphics such as charts 
or plots may represent a specific statistical 
view on a data set; the construction of that distinct 
perspective marshals formal data, such as dependent 
and independent variables, axes, scales, scaling 
factors (e.g. scalar multipliers or logarithms), and 
ranges.  In these examples, textual content is not only 
a presentation layer which merely exposits or 
reviews scientific frameworks; instead, 
the code describing textual structure and appearance 
reflects scientific paradigms and is therefore 
a theoretical artifact in its own right.
In particular, textual anchors and 
typesetting reflects not only raw text but structured 
data whose format and provenance represents specific 
scientific models.  Here it is valuable to 
cross-reference text with data sources:  
typesetting code may be generated directly from a 
data set, while the generated instructions (in \LaTeX{}, 
say) can trigger anchor labels and page references 
to be \q{forward-referenced} into the data set via 
auxiliary files.  Complete cross-references 
thereby integrate raw and textual data, 
yielding \textit{bi-directional} complex microcitations.  
 
\item{} A \Qt{}-based Reference Implementation which conveniently 
documents the \HTXN{} specifications.  With no external 
dependencies apart from \Qt{} Creator (a \Cpp{} Integrated 
Development Environment), authors can construct \HTXN{} documents 
via \NGML{} and, if desired, examine all parsing and encoding code 
(both statically and, dynamically, during document creation).  
The Reference Implementation also supports importing and 
conversions to \HTXN{} from \XML{}, using \Qt{}'s \XML{} module. 

\item{} Options for stashing compiled \HTXN{} documents in a 
database, so that saving files containing text serialization 
(in \NGML{}, for example) is not a prerequisite for maintaining 
persistent copies of \HTXN{} documents.  The Reference 
Implementation supports persistent 
\HTXN{} documents via the \WhiteDB{} database engine.

\item{} A flexible parsing engine which allows input languages 
for generating \HTXN{} documents to be customized and extended.
\end{enumerate}
}

%\vspace{2em}
%\noindent\lun{Architecture}
%{\sectsp}
\subsection{HTXN Architecture}

\p{Internally, \HTXN{} uses a Hypergraph representation where 
nodes are ranges pointing toward character streams in a 
separate multi-layered buffer (zero-length ranges represent 
anchors and locations within documents).  Ranges 
(and so therefore their corresponding nodes) can overlap 
or encompass one another in any combination.  The data 
establishing nodes' ranges and markup specifications (such as 
tag/command names) is separated from the text layers.}

\p{Also external to the text layers are extra data that affects 
the interpretation of individual characters (for 
example, to accommodate special symbols).  By factoring 
out this supplemental information, each \HTXN{} character 
has a consistent bit-length (typically one or two bytes, 
or a 10-bit pack corresponding to two base-32 digits).  
In general, each \HTXN{} character also has a visual 
representation (a \q{glyph}), because non-visual markup is 
modeled via standoff annotations rather than via content 
embedded in the text itself.  In particular, \HTXN{} does 
not internally use \XML{} entity references, Unicode points, 
diacritics, or other variant-length constructions where 
multiple physical characters correspond to one single 
text character.  Instead, any text character needing 
such supplemental detail is flagged via special codes, 
and an external table is used to retrieve that character's 
specifications.  The rationale for this design is to fully 
separate the markup-related processes of defining and 
annotating \textit{ranges}, from the text-encoding requirements 
concerning foreign letters, special symbols, and other 
nonstandard characters.}

\p{Instead of statically modeling character encodings, 
\HTXN{} provides an \textit{interface-based} encoding protocol.  
This means that \HTXN{} will recognize any encoding of a 
character, a character-set, a character-stream, 
and a character-stream offset range, so long as it is 
possible to obtain certain specific pieces of 
information with regard to the 
object in question.  At the lowest level, this 
means that character-sets and character-streams 
are implemented via \Cpp{} classes which inherit 
from an abstract base class.  Users can then 
build their own character sets by implementing 
their own \Cpp{} classes.  At a higher level, one 
character-set class can provide multiple 
character-set instances by loading data 
from an external file.  In either case, 
\HTXN{}'s character-encoding mechanism is 
orthogonal to encodings used for \XML{}, 
\LaTeX{}, Unicode, or any other markup/encoding format 
(though character sets can provide conversions 
to these formats as needed).  This promotes 
\HTXN{}'s capabilities to convert between and 
to integrate multiple markup protocols, 
such as \LaTeX{} and \XML{}.  More generally, it 
allows programmers to use Object-Oriented 
coding techniques to fine-tune the text-encoding 
process more aggressively than is possible 
with most markup and text-encoding formats.}

%\vspace{2em}
%\noindent\lun{Document Editing}
%{\sectsp}
\subsection{Document Editing}

\p{One benefit of \HTXN{} encoding concerns how 
\HTXN{} may be integrated with those application  
which allow multiple users to edit the text at hand.}

\p{As already described, a parent \HTXN{} 
document may be paired with a subordinate 
document providing restricted access to the 
parent.  This schema applies in contexts 
where only \textit{restricted editing} is 
appropriate.  In contrast to 
\textit{unrestricted editing}, restricted editing 
proceeds in the context of rules limiting 
which editing actions are possible.  In particular, 
restrictions may stipulate that only certain 
document content --- such as text that will be 
visible in the final publication --- may be 
modified.  Restrictions may also limit the degree 
to which a document's graph structure is altered.  
Added nodes, for example, may be required to fit 
inside other nodes (disabling interwoven markup that 
is normally accepted in \HTXN{}).  Added nodes 
may also be restricted to a subset of tags/commands, 
such as those providing visual markup 
(like italics and boldface) for published text, 
or metadata which permits annotations without changing 
the text or its appearance.}

\p{In order to enforce such restrictions, editors 
may be prevented from modifying \HTXN{} documents 
as raw text files; this in turn demands software 
which presents views onto documents' contents 
other than through text serialization.  For these use 
cases, \HTXN{} natively supports integration with 
\Qt{} applications.  In particular, subordinate 
\HTXN{} documents can be rendered via the 
\QTextDocument{} class, which allows restricted editing 
of visible textual content without directly 
changing the underlying \HTXN{} data.  
With \QTextDocument{}, editing actions can be 
initiated through a responsive native front end 
supporting context menus, secondary windows, 
undo/redo, and other convenient features 
associated with native desktop \GUI{}s.  
Alternatively, subordinate documents may be 
converted to \HTML{} and visualized through 
\QWebEngineView{}, which offers similar 
interactive functionality.}

\p{Each edit initiated through \QTextDocument{} 
or \QWebEngineView{} may then generate 
a data structure through which the 
changes are registered in subordinate and parent 
\HTXN{} documents.  These data structures, describing 
individual edits and groups of edits, may then be 
shared over \HTTP{} via \QNetworkManager{} and 
related classes.  This allows multiple users 
to synchronize their local document views in 
collaborative-editing contexts, and simultaneously allows 
publishers to track changes and maintain an official 
version for publication.  Maintaining one 
canonical document --- so that 
multiple users (e.g. authors, volume editors, series editors, 
and production editors) may update the document in real time 
--- is obviously more efficient than users 
sending successive copies of their document back 
and forth.  This, of course, is one reason 
why web-based collaborative editing is popular.  
The improvements introduced by \HTXN{} are first that 
co-edited documents are actually subordinate versions 
of parent documents which have more complex typesetting 
and metadata capabilities.  In so doing, the changes 
introduced in the subordinate document are thereby 
(as desired) reflected in the parent document.  Second, the 
editing \GUI{}s can be part of native-compiled applications 
with a full range of desktop-style functionality 
rather than web portals 
which have a more restricted interactive experience. 
In short, with the \HTXN{} framework  
the publication (books and journals) production process 
would be accelerated by virtue of \HTXN{}'s 
native-application features.  Other benefits 
of adopting \HTXN{} are identified in the 
following subsection.}

\subsection{HTXN Benefits}
\p{\lHTXN{} can generate documents in 
a variety of different representations 
(such as {\LaTeX}, {\XML}, {\HTML}, and 
{\RDF}), and enables publication workflows 
to combine two or more 
existing formats (e.g., {\LaTeX} and {\XML}).  
A document with \HTXN{} encoding will 
generate {\LaTeX} or {\XML} \q{views} 
which can each be constructed for use at different stages 
in the document-preparation pipeline.  \lHTXN{} is 
also designed to work with publications that are 
embedded in a larger data or multi-media ecosystem 
--- in particular, documents that are paired with 
data sets or multi-media content that need 
specialized software.  These priorities yield 
several benefits, including:

%\vspace{2.25em}
%\noindent\lun{Benefits}
%\vspace{-1em}


\begin{description}[leftmargin=13pt,labelsep=15pt,itemsep=12pt]
\item[Mix-and-Match Formats] \lHTXN{} employs 
\q{stand-off} annotation, which allows multiple markup 
protocols to be defined simultaneously on the same 
document.  In addition, \lHTXN{} uses a flexible 
character-encoding protocol that ensures 
compatibility with diverse text representations
(such as {\XML}, {\LaTeX}, Unicode, and {\Qt}/QString).  
Via secondary documents or \q{views} (generated from the primary 
\HTXN{} document), \HTXN{} can be used wherever 
{\XML} or {\LaTeX} (or other formats) are desired.   
   
\item[Fine-Grained Character Encoding] The \HTXN{} 
protocol includes more detailed document structure 
information compared to conventional 
markup.  For example, \HTXN{} identifies 
sentence boundaries and punctuation features, 
disambiguating logically distinct 
but often visually identical 
characters (such as \makebox{dots/periods or dashes/hyphens, 
which may have different structural meanings in different contexts}).   

\item[Multi-Media and Data Set Integration] 
\lHTXN{} is optimized for sophisticated 
publishing environments which combine 
conventional natural-language texts with 
interactive data sets and software.  
Contemporary publishing increasingly sees 
academic texts as part 
of a multi-faceted ecosystem, where  
publications, research data, and interactive 
software can be packaged into multi-media 
presentations.  \lHTXN{} ensures that 
documents can be properly experienced within these 
augmented publishing platforms.
\end{description}
}

%\vspace{-.5em}
%\noindent\lun{Complex Anchors and Interoperability}
\subsection{Complex Anchors and Interoperability}

\p{\lHTXN{} introduces a variation on micro-citations 
and conventional {\HTML} or {\LaTeX} anchors/labels, 
which we call \q{complex anchors}, to facilitate 
interoperability with research data sets 
and external software.  Complex anchors permit concepts, 
terms, and data structures to be tracked and cross-referenced 
between publications and their associated data sets or 
supplemental software.  Consider a table-structured 
data set whose columns represent scientific 
concepts or statistical parameters that are discussed in an associated publication (e.g. article or book chapter), 
or where data from a specific table is 
presented graphically as a figure within the publication.  Via 
complex anchors, these kinds of thematic relationships between 
data-set elements and corresponding points in 
the research text may be made explicit, 
so that data-set applications (including software 
expressly implemented for a newly published data set) 
can recognize references 
\q{pointing in} to the publication.  In the context of tabular data, 
data-set software could provide 
context-menu actions associated with 
each column (or, in the case of figure illustrations, the overall table), linking to an anchor in the text 
where the relevant concepts, terminology, 
or visualizations are explained.    
}

\p{This level of 
interoperation can be achieved by implementing 
document viewers (such as a \PDF{} viewer) embedded in 
scientific software or software expressly designed for 
a data set.  With embedded viewers, 
the operation of opening associated publications to 
specific anchor-points (such as figure illustrations) 
can be integrated as an interactive extension to 
their host applications, triggered by menu items 
or other {\GUI} components.  To support this 
interoperability, {\HTXN} provides anchors whose 
identifiers and embedded data can be customized 
to work with domain-specific host applications. 
}

%\vspace{2em}
%\noindent\lun{Complex Exolinks and Interoperability}
\subsection{Complex Exolinks and Interoperability}

\p{\HTXN{} \q{exolinks} refer to data or multi-media content \textit{outside} the text (so they 
are effectively the converse of 
complex anchors, which support 
references pointing \textit{inside} the text from 
external software components).  Complex 
exolinks designate 
data or multi-media content --- such as video, audio, or \ThreeD{} (scenes or panoramic-photography) graphics --- which are outside the text,  
but potentially part of a larger publication package 
wherein an article is accompanied by data sets and/or 
multimedia content.  
Traditional external/{\HTTP} references in {\HTML} or {\PDF} 
are designed to reference resources on the 
World Wide Web, but not content downloaded in a 
package along with publications themselves.
Therefore, special reference formats are required 
for document viewers to properly handle links in the 
text that point to non-web content (which is a technical 
limitation present in conventional document encoding 
formats).  {\lHTXN} will ensure that, when accessing multi-media content, properly encoded signals will be sent between the 
document-viewer components 
and applications which support the relevant 
multimedia file types (potentially host applications 
where the document viewers themselves may be embedded).}

\p{As a concrete example, consider 
a chemistry paper which  
is paired with {\ThreeD} descriptions of a 
particular molecule.  In order for readers to view this content, 
a signal needs to be sent to compatible molecular-visualization 
software (such as {\IQmol} --- to cite a 
\Qt{}-based, open-source 
case-study).  Analogously, when reading a paper concerning {\ThreeD} radiology, signals may be sent to --- or be read on components 
embedded within --- {\ThreeD} viewers such as  
{\MeshLab} (again \Qt{}/open-source).
To support interoperability requirements as shown 
by these examples, the \HTXN{} specification includes an 
\HTXN{}-specific \q{Native Application Network} (\HNaN{}) protocol to connect document viewers with 
external and/or host applications; 
\lHTXN{} exolinks encode data which ensures that 
the concordant \HNaN{} signals are properly generated.
}

\p{\lHTXN{} has numerous features for 
interoperation with software applications where document 
viewers may be embedded, or  
which support \HNaN{} via plugins.  In particular, 
\HTXN{} parsers and generators are provided via 
a \QtCpp{} library that can be dropped in to the 
source code of native \CLang{}/\Cpp{} applications, 
so it is straightforward to add \HNaN{} to existing 
software.  Based on \Qt{} (a \Cpp{} \GUI{} and 
application-development framework), 
\HTXN{} can leverage the full range of 
\Qt{} networking or front-end features (for instance, access to publishers' \API{}s can be 
introduced as a processing stage during 
document preparation).  In addition, \HTXN{}'s graph-based 
parsing framework and hypergraph-based annotation 
model can be customized and paired with project-specific 
\GUI{} components for viewing and accessing data 
sets.  Via such customizations, \HTXN{} can be 
adapted to provide a domain-specific publication 
platform for specific research projects or 
environments (individual journals, 
book series, research labs and academic departments, etc.).  
\lHTXN{}'s \q{reference implementation} includes a 
specially-designed \q{Next-Generation} markup language 
(\NGML{}), as one way to build \HTXN{} files.  The 
\NGML{} library is transparent and distributed 
in source-code form, so it can be modified 
to create domain-specific markup styles.  A 
customized version of \NGML{} can thereby be used 
to construct \HTXN{} documents according to each individual 
lab's or journal's specifications.}
